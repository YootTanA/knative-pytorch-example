**I have provided examples of how to use PyTorch inference model on Knative.**

Knative is a powerful tool for serving serverless applications on your cluster. However, I have not seen anyone share examples of how to deploy an inference model on a serverless platform.

In this example, I used pretrained models from [Pytorch Website](https://pytorch.org/vision/stable/models.html)  

To get started, you'll need a cluster to test this out.

Let go check this tutorial: https://knative.dev/docs/getting-started/. 
Choose your preferred cluster tool and try deploy my examples on your serverless platform. Enjoy!! 
